# Reformulation du sujet

# Notes de rÃ©union

<aside>
ğŸ“

- modÃ©liser le jeu
- reinforcement learning
- ajouter des rÃ¨gles (Ã  prÃ©voir pour lâ€™architecture)
- rÃ©cupÃ©rer les stats quand les agents jouent : analyse des diffÃ©rentes variantes
- quels critÃ¨res pour dire quâ€™un jeu est meilleur quâ€™un autre
</aside>

<aside>
ğŸ“

- agents
- changer leurs comportements
- chercher leurs comportements
</aside>

<aside>
ğŸ“

- diffÃ©rents styles dâ€™agents (Ã  dÃ©finir, â€œcaractÃ¨resâ€)
</aside>

<aside>
ğŸ²

Liste de jeux :

- Blokus
- Labyrinth
- Petits chevaux
- Snake-and-ladders
- Cluedo (complexitÃ© Ã©levÃ©)
- Bataille navale (Ã  2)
- Puissance 4 (Ã  2)
- Reversi othello (Ã  2)
- Carcassonne (version simplifiÃ©e)
</aside>

---

# Reformulation du sujet

### DÃ©veloppement dâ€™agents autonomes et crÃ©ation de nouvelles rÃ¨gles pour jeux de plateau via lâ€™apprentissage par renforcement

<aside>
ğŸ’¡

Description

Ce projet a pour objectif de crÃ©er des joueurs automatiques Ã  l'aide de techniques d'apprentissage par renforcement (RL), capables de maÃ®triser des jeux de plateau simulÃ©s informatiquement. 

Ces agents seront entraÃ®nÃ©s pour optimiser leurs stratÃ©gies en fonction des rÃ¨gles et des interactions avec d'autres joueurs (humains ou agents). 

En plus de jouer, ces agents seront utilisÃ©s pour tester de nouvelles rÃ¨gles de jeu et adapter leurs stratÃ©gies Ã  des scÃ©narios variÃ©s. 

Chaque agent aura un comportement diffÃ©rent, ce qui permettra d'analyser l'impact des variantes de rÃ¨gles sur l'Ã©quilibre et la â€œjouabilitÃ©â€ du jeu.

</aside>

<aside>
ğŸ’¡

Objectifs  

- EntraÃ®ner des agents RL pour qu'ils puissent jouer efficacement Ã  des jeux de plateau.
- Tester et optimiser les stratÃ©gies de jeu, amÃ©liorant ainsi l'Ã©quilibrage et la profondeur des jeux.
- Adapter les agents aux nouvelles rÃ¨gles ou variantes de jeu.
- Tester diffÃ©rentes mÃ©caniques de jeu grÃ¢ce Ã  des simulations massives.
- Personnaliser les agents selon divers styles de jeu.
- Optimiser les rÃ¨gles grÃ¢ce aux retours des simulations d'agents RL.
</aside>