### DÃ©veloppement dâ€™agents autonomes et crÃ©ation de nouvelles rÃ¨gles pour jeux de plateau via lâ€™apprentissage par renforcement

Projet realisÃ© dans le cadre de l'UE "Projet Master" en Master 2 Sciences des DonnÃ©es et SystÃ¨mes Complexes par:
- KRUZIC Charlotte
- MARQUIS ZoÃ©
- KUDRIASHOV Daniil
- ZAITCEVA Ekaterina

## Description

Ce projet a pour objectif de crÃ©er des joueurs automatiques Ã  l'aide de techniques d'apprentissage par renforcement (RL), capables de maÃ®triser des jeux de plateau simulÃ©s informatiquement. 

Ces agents seront entraÃ®nÃ©s pour optimiser leurs stratÃ©gies en fonction des rÃ¨gles et des interactions avec d'autres joueurs (humains ou agents). 

En plus de jouer, ces agents seront utilisÃ©s pour tester de nouvelles rÃ¨gles de jeu et adapter leurs stratÃ©gies Ã  des scÃ©narios variÃ©s. 

Chaque agent aura un comportement diffÃ©rent, ce qui permettra d'analyser l'impact des variantes de rÃ¨gles sur l'Ã©quilibre et la â€œjouabilitÃ©â€ du jeu.

## Objectifs  

- EntraÃ®ner des agents RL pour qu'ils puissent jouer efficacement Ã  des jeux de plateau.
- Tester et optimiser les stratÃ©gies de jeu, amÃ©liorant ainsi l'Ã©quilibrage et la profondeur des jeux.
- Adapter les agents aux nouvelles rÃ¨gles ou variantes de jeu.
- Tester diffÃ©rentes mÃ©caniques de jeu grÃ¢ce Ã  des simulations massives.
- Personnaliser les agents selon divers styles de jeu.
- Optimiser les rÃ¨gles grÃ¢ce aux retours des simulations d'agents RL.

## Installer les packages : 
    cd .\Labyrinth-Python\
    sudo apt install python3-pip  
    pip install -r requirements.txt

## Commandes Ã  exÃ©cuter pour pouvoir lancer le jeu 
    chmod u+x *
    cd .\Labyrinth-Python\
    python3 play.py [option]

Vous pouvez configurer le nombre total de joueurs, le nombre de joueurs humains et IA, ainsi que le thÃ¨me du jeu Ã  l'aide d'options passÃ©es en ligne de commande.

### Option
- `-j`, `--joueurs` : Nombre total de joueurs (par dÃ©faut : 2).
- `-hu`, `--humains` : Nombre de joueurs humains (par dÃ©faut : 0).
- `-ia`, `--intelligence-artificielle` : Nombre de joueurs IA (par dÃ©faut : 0).
- `-t`, `--theme` : Choix du thÃ¨me (disponibles : original, kity, par dÃ©faut : original).

! Si seul le nombre total de joueurs est precisÃ©, on considere que la partie se passe entre les joueurs IA.

## Test de l'environnement Gymnasium
### Execution rapide
Pour tester l'environnement de jeu `gym_env_2dim.py`, il faut lancer la commande suivante :  
```console
python3 ./main_env.py
```
Cette commande lance une partie entre deux agents RL jouant des actions alÃ©atoires dans l'environnement, et la visualisation en temps rÃ©el du jeu est assurÃ©e par le `GUI_manager`.

### Notebooks pour l'entainement des agents
Le notebook `entrainement_agents.ipynb` permet d'entraÃ®ner des agents RL sur l'environnement `gym_env_2dim.py`. Il enregistre les modÃ¨les d'agents entraÃ®nÃ©s et permet de suivre les mÃ©triques de performance avec TensorBoard.

Le notebook `notebook.ipynb` permet d'entraÃ®ner des agents sur l'ancien environnement `gym_env_labyrinthe.py`, qui est conÃ§u pour un seul agent jouant seul. Cet environnement a Ã©tÃ© abandonnÃ© au profit de gym_env_2dim.py.


## En cours ğŸ› ï¸
Pour la base de donnÃ©es : 

    sudo apt install postgresql postgresql-contrib
    sudo systemctl start postgresql
    sudo systemctl enable postgresql


lancer les tests
    python3 -m pytest tests_pytest


Choix entre 2, 3 et 4 joueurs.

RÃ¨gles qu'on peut faire changer : 

choisir entre 1 et 2 (exclusif, par dÃ©faut 1)
1. tous les chevaux d'un joueur doivent atteindre le centre du plateau pour gagner
2. le premier cheval au centre du plateau fait gagner son joueur 

choisir entre 2, 3, 4 (exclusif) (voire plus ?) chevaux par joueur
2. chaque joueur a 2 chevaux
3. chaque joueur a 3 chevaux
4. chaque joueur a 4 chevaux
5. chaque joueur a 5 chevaux
6. chaque joueur a 6 chevaux 

choisir entre atteindre exactement le pied de l'escalier pour pouvoir monter ou non 
0. pas beosin d'atteindre exactement le pied
1. atteindre exactement le pied de l'escalier (possible que si avec la valeur du dÃ© il se rapproche de l'objectif : TODO gestion si y a un autre joueur Ã  cet endroit lÃ )

si la derniÃ¨re rÃ©ponse Ã©tait 1:
0. monter de la valeur indiquÃ©e (si il fait plus que l'objectif, atteint quand mÃªme l'objectif)
1. monter exactement les marches 1 Ã  1 (faire 1 pour aller sur la case 1, 2 case 2, 3 case 3...) dans l'ordre et faire un 6 pour atteindre l'objectif 

TODO ZOE 
si la derniÃ¨re rÃ©ponse Ã©tait 1:
0. ne rejoue pas Ã  chaque fois qu'il monte d'une marche
1. rejoue Ã  chaque fois qu'il monte correctement une marche (raccourcir la partie)

attention : chemin et escalier : plusieurs pions du meme joueur autorisÃ©

TODO : gestion protect -> ne pas pouvoir kill / protect si on se mets dans la meme case
et dans espace observation reward si pions protÃ©gÃ©s, si plus pion protÃ©gÃ© -> reward nÃ©gatif ?

